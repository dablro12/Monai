{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 교수님이 말씀해주신 3D 여러 조직 segment 하는 방법 UNETR이용\n",
    "\n",
    "아래의 링크를 통해 튜토리얼 따라해볼 수 있음\n",
    "\n",
    "https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/unetr_btcv_segmentation_3d.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이번 튜토리얼은 어떻게 UNTETP을 이용해 workflow를 훈련시키는 방법에 대해 만들어볼 예정\n",
    "\n",
    "> 훈련 데이터 셋 : BTCV\n",
    "\n",
    "> 여러 조직들에 대한 segment를 진행해보자"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작업설명\n",
    "### 이번 작업에서는 총 6가지의 작업을 할 것이고 아래의 작업 설명을 보자.\n",
    "> 1. Transforms for dictionary format data.\n",
    "->딕셔너리형태의 데이터로 변환\n",
    "\n",
    "> 2. Define a new transform according to MONAI transform API.\n",
    "->Monai API에 맞게끔 새로운 형태로 정의 \n",
    "\n",
    "> 3. Load Nifti image with metadata, load a list of images and stack them.\n",
    "-> Nifti 이미지를 로드시키고, 그 이미지들을 리스트로 만듦\n",
    "\n",
    "> 4. Randomly adjust intensity for data augmentation.\n",
    "-> data augmentation을 위해 intensity를 랜덤하게 조절해줌 \n",
    "\n",
    "> 5. Cache IO and transforms to accelerate training and validation.\n",
    "-> 훈련 및 확인을 가속화시켜 Input/Output형태를 저장한다. \n",
    "\n",
    "> 6. 3D UNETR model, DiceCE loss function, Mean Dice metric for multi-organ segmentation task.\n",
    "-> 3D UNETR 과 DiceCE loss 함수, Dice metric 평균을 구해 segment의 성능을 확인하기 \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 주소\n",
    "https://www.synapse.org/#!Synapse:syn3193805/wiki/217752 \n",
    "\n",
    "#### <데이터 요약> 소화계 \n",
    "1. subjects : 50 people, cancer people\n",
    "\n",
    "2. Data type : CT scan \n",
    "\n",
    "3. Target : 13 abdominal organs (1. Spleen 2. Right Kidney 3. Left Kideny 4.Gallbladder 5.Esophagus 6. Liver 7. Stomach 8.Aorta 9. IVC 10. Portal and Splenic Veins 11. Pancreas 12 Right adrenal gland 13 Left adrenal gland.)\n",
    "\n",
    "4. Modality : CT Size : 30, 3D vol (24 Training + 6 Testing)\n",
    "\n",
    "5. Challenge(비교) : BTCV MICCAI Challenge\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 작업 시작 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 설치환경 : Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pip install -q \"monai-weekly[nibabel, tqdm, einops]\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 설치모듈 : Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.dev2304\n",
      "Numpy version: 1.23.3\n",
      "Pytorch version: 1.13.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 9a57be5aab9f2c2a134768c0c146399150e247a0\n",
      "MONAI __file__: /Users/choedaehyeon/Library/Python/3.9/lib/python/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.2.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.2\n",
      "pandas version: 1.5.1\n",
      "einops version: 0.6.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil  \n",
    "import tempfile \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm \n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 디렉토리 경로 가지고오기 : Setup data directory\n",
    "MONAI_DATA_DIRECTORY 에서 데이터를 가지고 올것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/qstscrlx4tsddzht4m9xgdcm0000gn/T/tmpq6b5vaww\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get('/Users/choedaehyeon/Monai/data')\n",
    "\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory \n",
    "print(root_dir) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 데이터 training 및 검수 할 셋업 만들기 : Setup transforms for training and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련할 변형 방법들 설정 \n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#형태 어떻게 변형줄건지 \n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 데이터셋 다운로드해서 가지고 오고 포맷팅 시키기 : Download dataset and format in the folder.\n",
    "\n",
    "1. Download dataset from here: https://www.synapse.org/#!Synapse:syn3193805/wiki/89480\\n\n",
    "2. Put images in the ./data/imagesTr\n",
    "3. Put labels in the ./data/labelsTr\n",
    "4. make JSON file accordingly: ./data/dataset_0.json\n",
    "\n",
    "> 훈련데이터셋 24개, 테스트데이터셋 6개 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data list file /dataset/dataset_0.json does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m split_json \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdataset_0.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m datasets \u001b[39m=\u001b[39m data_dir \u001b[39m+\u001b[39m split_json\n\u001b[0;32m----> 5\u001b[0m datalist \u001b[39m=\u001b[39m load_decathlon_datalist(datasets, \u001b[39mTrue\u001b[39;49;00m, \u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m val_files \u001b[39m=\u001b[39m load_decathlon_datalist(datasets, \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m train_ds \u001b[39m=\u001b[39m CacheDataset(\n\u001b[1;32m      8\u001b[0m     data\u001b[39m=\u001b[39mdatalist,\n\u001b[1;32m      9\u001b[0m     transform\u001b[39m=\u001b[39mtrain_transforms,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/monai/data/decathlon_datalist.py:122\u001b[0m, in \u001b[0;36mload_decathlon_datalist\u001b[0;34m(data_list_file_path, is_segmentation, data_list_key, base_dir)\u001b[0m\n\u001b[1;32m    120\u001b[0m data_list_file_path \u001b[39m=\u001b[39m Path(data_list_file_path)\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data_list_file_path\u001b[39m.\u001b[39mis_file():\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mData list file \u001b[39m\u001b[39m{\u001b[39;00mdata_list_file_path\u001b[39m}\u001b[39;00m\u001b[39m does not exist.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(data_list_file_path) \u001b[39mas\u001b[39;00m json_file:\n\u001b[1;32m    124\u001b[0m     json_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(json_file)\n",
      "\u001b[0;31mValueError\u001b[0m: Data list file /dataset/dataset_0.json does not exist."
     ]
    }
   ],
   "source": [
    "data_dir = \"/dataset/\"\n",
    "split_json = \"dataset_0.json\"\n",
    "\n",
    "datasets = data_dir + split_json\n",
    "datalist = load_decathlon_datalist(datasets, True, \"training\")\n",
    "val_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "train_ds = CacheDataset(\n",
    "    data=datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=24,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=8,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=1, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files, transform=val_transforms, cache_num=6, cache_rate=1.0, num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
